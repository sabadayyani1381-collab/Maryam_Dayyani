{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4df2c6d6",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI \n",
    "\n",
    "Go to:\n",
    "```\n",
    "https://platform.openai.com/docs/quickstart\n",
    "```\n",
    "Install:\n",
    "```\n",
    "pip install openai\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d25278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display\n",
    "from openai import OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "600075de",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Check the key\n",
    "if not API_KEY:\n",
    "    print(\"No API key was found!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ed08a5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "{\n",
      "  \"id\": \"resp_0d73eaa98f43787c00691f06d2d2d48192947d1ec7dc1fb5a6\",\n",
      "  \"object\": \"response\",\n",
      "  \"created_at\": 1763641042,\n",
      "  \"status\": \"completed\",\n",
      "  \"background\": false,\n",
      "  \"billing\": {\n",
      "    \"payer\": \"developer\"\n",
      "  },\n",
      "  \"error\": null,\n",
      "  \"incomplete_details\": null,\n",
      "  \"instructions\": null,\n",
      "  \"max_output_tokens\": null,\n",
      "  \"max_tool_calls\": null,\n",
      "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
      "  \"output\": [\n",
      "    {\n",
      "      \"id\": \"msg_0d73eaa98f43787c00691f06d3b7bc819282f0408b50008009\",\n",
      "      \"type\": \"message\",\n",
      "      \"status\": \"completed\",\n",
      "      \"content\": [\n",
      "        {\n",
      "          \"type\": \"output_text\",\n",
      "          \"annotations\": [],\n",
      "          \"logprobs\": [],\n",
      "          \"text\": \"\\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0648 \\u0633\\u06cc\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062f\\u0648 \\u0646\\u0648\\u0639 \\u0645\\u062e\\u062a\\u0644\\u0641 \\u0627\\u0632 \\u0627\\u062c\\u0631\\u0627\\u0645 \\u0622\\u0633\\u0645\\u0627\\u0646\\u06cc \\u0647\\u0633\\u062a\\u0646\\u062f \\u06a9\\u0647 \\u062a\\u0641\\u0627\\u0648\\u062a\\u200c\\u0647\\u0627\\u06cc \\u0632\\u06cc\\u0627\\u062f\\u06cc \\u0628\\u0627 \\u0647\\u0645 \\u062f\\u0627\\u0631\\u0646\\u062f:\\n\\n### \\u0633\\u062a\\u0627\\u0631\\u0647:\\n1. **\\u0646\\u0648\\u0631 \\u062a\\u0648\\u0644\\u06cc\\u062f\\u06cc**: \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062e\\u0648\\u062f\\u0634\\u0627\\u0646 \\u0646\\u0648\\u0631 \\u062a\\u0648\\u0644\\u06cc\\u062f \\u0645\\u06cc\\u200c\\u06a9\\u0646\\u0646\\u062f\\u060c \\u0628\\u0647 \\u062f\\u0644\\u06cc\\u0644 \\u0641\\u0631\\u0622\\u06cc\\u0646\\u062f\\u0647\\u0627\\u06cc \\u0647\\u0645\\u062c\\u0648\\u0634\\u06cc \\u0647\\u0633\\u062a\\u0647\\u200c\\u0627\\u06cc \\u06a9\\u0647 \\u062f\\u0631 \\u062f\\u0631\\u0648\\u0646 \\u0622\\u0646\\u200c\\u0647\\u0627 \\u0631\\u062e \\u0645\\u06cc\\u200c\\u062f\\u0647\\u062f.\\n2. **\\u062a\\u0628\\u0635\\u0631\\u0647\\u200c\\u0647\\u0627\\u06cc \\u0641\\u06cc\\u0632\\u06cc\\u06a9\\u06cc**: \\u0645\\u0639\\u0645\\u0648\\u0644\\u0627\\u064b \\u0627\\u0632 \\u0647\\u06cc\\u062f\\u0631\\u0648\\u0698\\u0646 \\u0648 \\u0647\\u0644\\u06cc\\u0648\\u0645 \\u062a\\u0634\\u06a9\\u06cc\\u0644 \\u0634\\u062f\\u0647 \\u0648 \\u0628\\u0647 \\u0648\\u0627\\u0633\\u0637\\u0647 \\u0646\\u06cc\\u0631\\u0648\\u06cc \\u06af\\u0631\\u0627\\u0646\\u0634\\u060c \\u062c\\u0631\\u0645 \\u0628\\u0633\\u06cc\\u0627\\u0631 \\u0632\\u06cc\\u0627\\u062f\\u06cc \\u062f\\u0627\\u0631\\u0646\\u062f.\\n3. **\\u062d\\u0631\\u0627\\u0631\\u062a \\u0648 \\u0631\\u0648\\u0634\\u0646\\u0627\\u06cc\\u06cc**: \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062f\\u0645\\u0627\\u06cc \\u0628\\u0633\\u06cc\\u0627\\u0631 \\u0628\\u0627\\u0644\\u0627\\u06cc\\u06cc \\u062f\\u0627\\u0631\\u0646\\u062f \\u0648 \\u0628\\u0647 \\u0647\\u0645\\u06cc\\u0646 \\u062f\\u0644\\u06cc\\u0644 \\u062f\\u0631 \\u0622\\u0633\\u0645\\u0627\\u0646 \\u0646\\u0648\\u0631\\u0627\\u0646\\u06cc \\u0628\\u0647 \\u0646\\u0638\\u0631 \\u0645\\u06cc\\u200c\\u0631\\u0633\\u0646\\u062f.\\n\\n### \\u0633\\u06cc\\u0627\\u0631\\u0647:\\n1. **\\u0639\\u062f\\u0645 \\u0646\\u0648\\u0631 \\u0645\\u0633\\u062a\\u0642\\u0644**: \\u0633\\u06cc\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062e\\u0648\\u062f\\u0634\\u0627\\u0646 \\u0646\\u0648\\u0631 \\u062a\\u0648\\u0644\\u06cc\\u062f \\u0646\\u0645\\u06cc\\u200c\\u06a9\\u0646\\u0646\\u062f \\u0648 \\u0628\\u0647 \\u0647\\u0645\\u06cc\\u0646 \\u062f\\u0644\\u06cc\\u0644 \\u0648\\u0642\\u062a\\u06cc \\u0646\\u0648\\u0631 \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 (\\u0645\\u062b\\u0644 \\u062e\\u0648\\u0631\\u0634\\u06cc\\u062f) \\u0628\\u0647 \\u0622\\u0646\\u200c\\u0647\\u0627 \\u0645\\u06cc\\u200c\\u062a\\u0627\\u0628\\u062f\\u060c \\u0645\\u06cc\\u200c\\u062f\\u0631\\u062e\\u0634\\u0646\\u062f.\\n2. **\\u0645\\u062f\\u0627\\u0631**: \\u0633\\u06cc\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062f\\u0631 \\u0645\\u062f\\u0627\\u0631\\u0647\\u0627\\u06cc \\u0645\\u0634\\u062e\\u0635\\u06cc \\u0628\\u0647 \\u062f\\u0648\\u0631 \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u062d\\u0631\\u06a9\\u062a \\u0645\\u06cc\\u200c\\u06a9\\u0646\\u0646\\u062f \\u0648 \\u0633\\u0628\\u06a9\\u200c\\u062a\\u0631 \\u0627\\u0632 \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0647\\u0633\\u062a\\u0646\\u062f.\\n3. **\\u062a\\u0631\\u06a9\\u06cc\\u0628 \\u0645\\u0648\\u0627\\u062f**: \\u0633\\u06cc\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0645\\u0645\\u06a9\\u0646 \\u0627\\u0633\\u062a \\u0627\\u0632 \\u0633\\u0646\\u06af\\u060c \\u06af\\u0627\\u0632 \\u06cc\\u0627 \\u06cc\\u062e \\u062a\\u0634\\u06a9\\u06cc\\u0644 \\u0634\\u062f\\u0647 \\u0628\\u0627\\u0634\\u0646\\u062f \\u0648 \\u0628\\u0647 \\u0637\\u0648\\u0631 \\u06a9\\u0644\\u06cc \\u062f\\u0627\\u0631\\u0627\\u06cc \\u0633\\u0627\\u062e\\u062a\\u0627\\u0631 \\u0645\\u062a\\u0641\\u0627\\u0648\\u062a\\u06cc \\u0646\\u0633\\u0628\\u062a \\u0628\\u0647 \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0647\\u0633\\u062a\\u0646\\u062f.\\n\\n### \\u062e\\u0644\\u0627\\u0635\\u0647:\\n\\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0646\\u0648\\u0631 \\u062a\\u0648\\u0644\\u06cc\\u062f \\u0645\\u06cc\\u200c\\u06a9\\u0646\\u0646\\u062f \\u0648 \\u062f\\u0631 \\u0645\\u0631\\u06a9\\u0632 \\u06a9\\u0647\\u06a9\\u0634\\u0627\\u0646\\u200c\\u0647\\u0627 \\u0648 \\u0633\\u06cc\\u0633\\u062a\\u0645\\u200c\\u0647\\u0627\\u06cc \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0627\\u06cc \\u0642\\u0631\\u0627\\u0631 \\u062f\\u0627\\u0631\\u0646\\u062f\\u060c \\u062f\\u0631 \\u062d\\u0627\\u0644\\u06cc \\u06a9\\u0647 \\u0633\\u06cc\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0628\\u0647 \\u062f\\u0648\\u0631 \\u0633\\u062a\\u0627\\u0631\\u0647\\u200c\\u0647\\u0627 \\u0645\\u06cc\\u200c\\u0686\\u0631\\u062e\\u0646\\u062f \\u0648 \\u062e\\u0648\\u062f\\u0634\\u0627\\u0646 \\u0646\\u0648\\u0631 \\u062f\\u0627\\u062e\\u0644\\u06cc \\u0646\\u062f\\u0627\\u0631\\u0646\\u062f.\"\n",
      "        }\n",
      "      ],\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  ],\n",
      "  \"parallel_tool_calls\": true,\n",
      "  \"previous_response_id\": null,\n",
      "  \"prompt_cache_key\": null,\n",
      "  \"prompt_cache_retention\": null,\n",
      "  \"reasoning\": {\n",
      "    \"effort\": null,\n",
      "    \"summary\": null\n",
      "  },\n",
      "  \"safety_identifier\": null,\n",
      "  \"service_tier\": \"default\",\n",
      "  \"store\": true,\n",
      "  \"temperature\": 1.0,\n",
      "  \"text\": {\n",
      "    \"format\": {\n",
      "      \"type\": \"text\"\n",
      "    },\n",
      "    \"verbosity\": \"medium\"\n",
      "  },\n",
      "  \"tool_choice\": \"auto\",\n",
      "  \"tools\": [],\n",
      "  \"top_logprobs\": 0,\n",
      "  \"top_p\": 1.0,\n",
      "  \"truncation\": \"disabled\",\n",
      "  \"usage\": {\n",
      "    \"input_tokens\": 16,\n",
      "    \"input_tokens_details\": {\n",
      "      \"cached_tokens\": 0\n",
      "    },\n",
      "    \"output_tokens\": 322,\n",
      "    \"output_tokens_details\": {\n",
      "      \"reasoning_tokens\": 0\n",
      "    },\n",
      "    \"total_tokens\": 338\n",
      "  },\n",
      "  \"user\": null,\n",
      "  \"metadata\": {}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.openai.com/v1/responses\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"input\": \"فرق ستاره و سیاره چیه؟\"\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "print(response.status_code)\n",
    "print(json.dumps(response.json(), indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f697190e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "ستاره‌ها و سیاره‌ها دو نوع مختلف از اجرام آسمانی هستند که تفاوت‌های زیادی با هم دارند:\n",
       "\n",
       "### ستاره:\n",
       "1. **نور تولیدی**: ستاره‌ها خودشان نور تولید می‌کنند، به دلیل فرآیندهای همجوشی هسته‌ای که در درون آن‌ها رخ می‌دهد.\n",
       "2. **تبصره‌های فیزیکی**: معمولاً از هیدروژن و هلیوم تشکیل شده و به واسطه نیروی گرانش، جرم بسیار زیادی دارند.\n",
       "3. **حرارت و روشنایی**: ستاره‌ها دمای بسیار بالایی دارند و به همین دلیل در آسمان نورانی به نظر می‌رسند.\n",
       "\n",
       "### سیاره:\n",
       "1. **عدم نور مستقل**: سیاره‌ها خودشان نور تولید نمی‌کنند و به همین دلیل وقتی نور ستاره‌ها (مثل خورشید) به آن‌ها می‌تابد، می‌درخشند.\n",
       "2. **مدار**: سیاره‌ها در مدارهای مشخصی به دور ستاره‌ها حرکت می‌کنند و سبک‌تر از ستاره‌ها هستند.\n",
       "3. **ترکیب مواد**: سیاره‌ها ممکن است از سنگ، گاز یا یخ تشکیل شده باشند و به طور کلی دارای ساختار متفاوتی نسبت به ستاره‌ها هستند.\n",
       "\n",
       "### خلاصه:\n",
       "ستاره‌ها نور تولید می‌کنند و در مرکز کهکشان‌ها و سیستم‌های ستاره‌ای قرار دارند، در حالی که سیاره‌ها به دور ستاره‌ها می‌چرخند و خودشان نور داخلی ندارند."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = response.json()\n",
    "display(Markdown(res[\"output\"][0][\"content\"][0][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd635afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "b'event: response.created'\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m line:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(line)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     data = \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m     \u001b[38;5;28mprint\u001b[39m(data)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    341\u001b[39m     s = s.decode(detect_encoding(s), \u001b[33m'\u001b[39m\u001b[33msurrogatepass\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    348\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONDecoder\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    332\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w=WHITESPACE.match):\n\u001b[32m    333\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03m    containing a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m     obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m     end = _w(s, end).end()\n\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m end != \u001b[38;5;28mlen\u001b[39m(s):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    353\u001b[39m     obj, end = \u001b[38;5;28mself\u001b[39m.scan_once(s, idx)\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "url = \"https://api.openai.com/v1/responses\"\n",
    "\n",
    "headers = {\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "}\n",
    "\n",
    "payload = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"input\": \"یک خلاصه کوتاه در مورد به وجود آمدن مدل های زبانی بزرگ بگو\",\n",
    "    \"stream\": True\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=payload)\n",
    "\n",
    "print(response.status_code)\n",
    "# print(response.text)\n",
    "# print(json.dumps(response.json(), indent=2))\n",
    "\n",
    "with requests.post(url, headers=headers, json=payload, stream=True) as r:\n",
    "    for line in r.iter_lines():\n",
    "        if line:\n",
    "            print(line)\n",
    "            data = json.loads(line.decode(\"utf-8\"))\n",
    "            print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c977f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f54f1a",
   "metadata": {},
   "source": [
    "# Frontier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bfd86b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Welcome! I'm glad you're here and excited to chat with you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "message = \"Hello, GPT! This is my first ever message to you!\"\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\":\"user\", \"content\":message}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a17af4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A class to represent a Webpage\n",
    "# If you're not familiar with Classes, check out the \"Intermediate Python\" notebook\n",
    "\n",
    "# Some websites need you to use proper headers when fetching them:\n",
    "headers = {\n",
    " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
    "}\n",
    "\n",
    "class Website:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        \"\"\"\n",
    "        Create this Website object from the given url using the BeautifulSoup library\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        response = requests.get(url, headers=headers)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            irrelevant.decompose()\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f85685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try one out. Change the website and add print statements to follow along.\n",
    "\n",
    "person = Website(\"https://fa.wikipedia.org/wiki/%D8%AD%D8%A7%D9%81%D8%B8\")\n",
    "print(person.title)\n",
    "print(person.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201a160e",
   "metadata": {},
   "source": [
    "## Types of prompts\n",
    "\n",
    "Models like GPT4o have been trained to receive instructions in a particular way.\n",
    "\n",
    "They expect to receive:\n",
    "\n",
    "**A system prompt** that tells them what task they are performing and what tone they should use\n",
    "\n",
    "**A user prompt** -- the conversation starter that they should reply to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb63eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define our system prompt - you can experiment with this later, changing the last sentence to 'Respond in markdown in Spanish.\"\n",
    "\n",
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1258e31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function that writes a User Prompt that asks for summaries of websites:\n",
    "\n",
    "def user_prompt_for(website):\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    user_prompt += website.text\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f2a54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(user_prompt_for(person))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f6252",
   "metadata": {},
   "source": [
    "## Messages\n",
    "\n",
    "The API from OpenAI expects to receive messages in a particular structure.\n",
    "Many of the other APIs share this structure:\n",
    "\n",
    "```python\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message goes here\"},\n",
    "    {\"role\": \"user\", \"content\": \"user message goes here\"}\n",
    "]\n",
    "```\n",
    "To give you a preview, the next 2 cells make a rather simple call - we won't stretch the mighty GPT (yet!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d2acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"شما یک دستیار شوخ طبع هستید\"},\n",
    "    {\"role\": \"user\", \"content\": \"۲ + ۲ چند میشه؟\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcbc557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To give you a preview -- calling OpenAI with system and user messages:\n",
    "\n",
    "response = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13621b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See how this function creates exactly the format above\n",
    "\n",
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7543096",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_for(person)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2a5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And now: call the OpenAI API. You will get very familiar with this!\n",
    "\n",
    "def summarize(url):\n",
    "    website = Website(url)\n",
    "    response = openai.chat.completions.create(\n",
    "        model = \"gpt-4o-mini\",\n",
    "        messages = messages_for(website)\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f84fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize(\"https://fa.wikipedia.org/wiki/%D8%AD%D8%A7%D9%81%D8%B8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b0ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to display this nicely in the Jupyter output, using markdown\n",
    "\n",
    "def display_summary(url):\n",
    "    summary = summarize(url)\n",
    "    display(Markdown(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a83470",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_summary(\"https://fa.wikipedia.org/wiki/%D8%AD%D8%A7%D9%81%D8%B8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956df924",
   "metadata": {},
   "source": [
    "# Open Source model\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76d4cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e7eb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b32f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85be5651",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e1fce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41b9ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422d2246",
   "metadata": {},
   "source": [
    "# Avalai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2028e2cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
